#!/bin/bash

# Fix aioredis Version Compatibility Issue
# Fixes: TypeError: duplicate base class TimeoutError

echo "üîß Fixing aioredis version compatibility issue..."

# Stop the problematic container
echo "üõë Stopping gateway container..."
docker stop synapse-gateway 2>/dev/null || true
docker rm synapse-gateway 2>/dev/null || true

# Option 1: Use compatible aioredis version
echo "üì¶ Creating compatible requirements.txt..."
cat > services/gateway/requirements.txt << 'EOF'
fastapi==0.104.1
uvicorn[standard]==0.24.0
redis==5.0.1
asyncpg==0.29.0
pydantic==2.5.0
prometheus-client==0.19.0
aiohttp==3.8.0
EOF

echo "‚úÖ Switched from aioredis to redis (more compatible)"

# Create updated main.py with redis instead of aioredis
echo "üîß Creating updated main.py with redis library..."
cat > services/gateway/main.py << 'EOF'
# services/gateway/main.py - Using redis instead of aioredis
import asyncio
import json
import logging
import time
import uuid
from typing import Dict, Any, Optional
from datetime import datetime, timezone

# Use redis instead of aioredis for better Python 3.11+ compatibility
try:
    import redis.asyncio as aioredis
    REDIS_AVAILABLE = True
except ImportError:
    try:
        import redis
        # Create async wrapper for redis
        class AsyncRedisWrapper:
            def __init__(self, redis_client):
                self._client = redis_client
            
            async def ping(self):
                return self._client.ping()
            
            async def lpush(self, key, value):
                return self._client.lpush(key, value)
            
            async def hmset(self, key, mapping):
                return self._client.hmset(key, mapping)
            
            async def expire(self, key, seconds):
                return self._client.expire(key, seconds)
            
            async def close(self):
                self._client.close()
        
        aioredis = None
        REDIS_AVAILABLE = True
    except ImportError:
        REDIS_AVAILABLE = False

try:
    import asyncpg
    POSTGRES_AVAILABLE = True
except ImportError:
    POSTGRES_AVAILABLE = False
    asyncpg = None

from fastapi import FastAPI, HTTPException, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI(title="SynapseGrid Gateway", version="2.0.2-redis-fixed")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class SubmitJobRequest(BaseModel):
    model_name: str
    input_data: Dict[str, Any]
    priority: int = 1
    timeout: int = 300
    gpu_requirements: Optional[Dict[str, Any]] = None

# Mock Redis for fallback
class MockRedis:
    async def ping(self):
        return b"PONG"
    
    async def lpush(self, key, value):
        logger.info(f"Mock Redis LPUSH: {key}")
        return 1
    
    async def hmset(self, key, mapping):
        logger.info(f"Mock Redis HMSET: {key}")
        return True
        
    async def expire(self, key, seconds):
        return True
        
    async def close(self):
        pass

# Utility functions
def generate_job_id() -> str:
    timestamp = int(time.time() * 1000)
    random_part = uuid.uuid4().hex[:8]
    return f"job_{timestamp}_{random_part}"

def verify_token(token: str) -> bool:
    return token in ["test-token", "dev-token", "admin-token"]

def get_utc_now() -> datetime:
    return datetime.now(timezone.utc)

def format_for_json(dt: datetime) -> str:
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return dt.isoformat()

# Global state
redis_client = None
postgres_pool = None

@app.on_event("startup")
async def startup():
    global redis_client, postgres_pool
    
    logger.info("üöÄ Starting SynapseGrid Gateway (Redis Fixed Version)...")
    
    # Initialize Redis with better compatibility
    try:
        if REDIS_AVAILABLE:
            # Try modern redis.asyncio first
            if hasattr(aioredis, 'from_url'):
                redis_client = aioredis.from_url(
                    "redis://redis:6379",
                    encoding="utf-8",
                    decode_responses=True,
                    socket_timeout=10
                )
                await redis_client.ping()
                logger.info("‚úÖ Connected to Redis (using redis.asyncio)")
            else:
                # Fallback to sync redis with async wrapper
                import redis
                sync_redis = redis.Redis(host='redis', port=6379, decode_responses=True)
                redis_client = AsyncRedisWrapper(sync_redis)
                await redis_client.ping()
                logger.info("‚úÖ Connected to Redis (using sync wrapper)")
        else:
            redis_client = MockRedis()
            logger.warning("‚ö†Ô∏è  Using mock Redis (library not available)")
            
    except Exception as e:
        logger.error(f"‚ùå Redis connection failed: {e}")
        redis_client = MockRedis()
        logger.warning("‚ö†Ô∏è  Falling back to mock Redis")
    
    # Initialize PostgreSQL
    try:
        if POSTGRES_AVAILABLE:
            postgres_pool = await asyncpg.create_pool(
                "postgresql://synapse:synapse123@postgres:5432/synapse",
                min_size=1,
                max_size=3,
                command_timeout=30
            )
            
            # Test connection and create table if needed
            async with postgres_pool.acquire() as conn:
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS jobs (
                        job_id VARCHAR(50) PRIMARY KEY,
                        client_id VARCHAR(100) NOT NULL,
                        model_name VARCHAR(100) NOT NULL,
                        input_data JSONB NOT NULL,
                        status VARCHAR(20) NOT NULL DEFAULT 'queued',
                        created_at TIMESTAMP WITH TIME ZONE NOT NULL,
                        estimated_cost NUMERIC(10,4) DEFAULT 0.0,
                        priority INTEGER DEFAULT 1
                    );
                """)
                await conn.fetchval("SELECT 1")
                
            logger.info("‚úÖ Connected to PostgreSQL")
        else:
            logger.warning("‚ö†Ô∏è  PostgreSQL not available (asyncpg missing)")
            
    except Exception as e:
        logger.error(f"‚ùå PostgreSQL connection failed: {e}")
        postgres_pool = None
    
    logger.info("üéâ Gateway startup complete!")

@app.on_event("shutdown")
async def shutdown():
    if redis_client and hasattr(redis_client, 'close'):
        await redis_client.close()
    if postgres_pool:
        await postgres_pool.close()
    logger.info("üõë Gateway shutdown complete")

@app.get("/health")
async def health_check():
    try:
        health_status = {
            "status": "healthy",
            "timestamp": format_for_json(get_utc_now()),
            "version": "2.0.2-redis-fixed",
            "services": {}
        }
        
        # Test Redis
        try:
            result = await redis_client.ping()
            if result in [b"PONG", "PONG", True]:
                health_status["services"]["redis"] = "healthy"
            else:
                health_status["services"]["redis"] = f"unexpected: {result}"
        except Exception as e:
            health_status["services"]["redis"] = f"error: {str(e)}"
        
        # Test PostgreSQL
        if postgres_pool:
            try:
                async with postgres_pool.acquire() as conn:
                    await conn.fetchval("SELECT 1")
                health_status["services"]["postgres"] = "healthy"
            except Exception as e:
                health_status["services"]["postgres"] = f"error: {str(e)}"
        else:
            health_status["services"]["postgres"] = "not_configured"
        
        return health_status
        
    except Exception as e:
        logger.error(f"‚ùå Health check failed: {e}")
        raise HTTPException(
            status_code=503,
            detail={
                "status": "unhealthy",
                "error": str(e),
                "timestamp": format_for_json(get_utc_now())
            }
        )

@app.post("/submit")
async def submit_job(
    request: SubmitJobRequest,
    authorization: str = Header(...),
    x_client_id: str = Header(..., alias="X-Client-ID")
):
    # Verify token
    token = authorization.replace("Bearer ", "").strip()
    if not verify_token(token):
        raise HTTPException(status_code=401, detail="Invalid token")
    
    # Generate job
    job_id = generate_job_id()
    now = get_utc_now()
    
    job_data = {
        "job_id": job_id,
        "client_id": x_client_id,
        "model_name": request.model_name,
        "input_data": request.input_data,
        "priority": request.priority,
        "timeout": request.timeout,
        "gpu_requirements": request.gpu_requirements or {},
        "created_at": format_for_json(now),
        "status": "pending"
    }
    
    try:
        # Add to Redis queue
        await redis_client.lpush("jobs:queue:eu-west-1", json.dumps(job_data))
        
        # Store job metadata
        job_key = f"job:{job_id}"
        await redis_client.hmset(job_key, {
            "job_id": job_id,
            "status": "pending",
            "created_at": format_for_json(now),
            "client_id": x_client_id
        })
        await redis_client.expire(job_key, 3600)
        
        # Store in PostgreSQL if available
        if postgres_pool:
            async with postgres_pool.acquire() as conn:
                await conn.execute("""
                    INSERT INTO jobs (
                        job_id, client_id, model_name, input_data, 
                        status, created_at, estimated_cost, priority
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                """, 
                job_id, x_client_id, request.model_name, 
                json.dumps(request.input_data), "pending", 
                now, 0.01, request.priority
                )
        
        logger.info(f"üì§ Job {job_id} submitted by {x_client_id}")
        
        return {
            "job_id": job_id,
            "status": "pending",
            "estimated_cost": 0.01,
            "message": "Job submitted successfully",
            "submitted_at": format_for_json(now)
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error submitting job: {e}")
        raise HTTPException(status_code=500, detail=f"Job submission failed: {str(e)}")

@app.get("/jobs/{job_id}")
async def get_job_status(job_id: str):
    """Get job status"""
    try:
        return {
            "job_id": job_id,
            "status": "pending",
            "created_at": format_for_json(get_utc_now()),
            "message": "Job status endpoint working"
        }
    except Exception as e:
        logger.error(f"‚ùå Error getting job status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/nodes")
async def list_nodes():
    """List available nodes"""
    return {
        "docker_nodes": 1,
        "native_nodes": 0,
        "total": 1,
        "message": "Node listing working"
    }

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0", 
        port=8080,
        log_level="info",
        reload=False
    )
EOF

echo "‚úÖ Updated main.py with redis compatibility fix"

# Update Dockerfile for better compatibility
echo "üê≥ Updating Dockerfile..."
cat > services/gateway/Dockerfile << 'EOF'
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .

# Upgrade pip and install requirements
RUN pip install --no-cache-dir --upgrade pip setuptools wheel
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY main.py .

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=15s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# Run the application
CMD ["python", "main.py"]
EOF

echo "‚úÖ Updated Dockerfile"

# Rebuild with clean build (no cache)
echo "üî® Rebuilding gateway container (no cache)..."
if command -v docker-compose >/dev/null 2>&1; then
    docker-compose build --no-cache gateway
    echo "üöÄ Starting gateway..."
    docker-compose up -d gateway
elif command -v docker >/dev/null 2>&1 && docker compose version >/dev/null 2>&1; then
    docker compose build --no-cache gateway
    echo "üöÄ Starting gateway..."
    docker compose up -d gateway
else
    echo "‚ùå Docker compose not available"
    exit 1
fi

echo "‚è≥ Waiting for gateway to start (30s)..."
sleep 30

# Test the gateway
echo "üß™ Testing gateway..."
for i in {1..5}; do
    if curl -s --max-time 10 http://localhost:8080/health >/dev/null; then
        echo "‚úÖ Gateway is responding!"
        echo ""
        echo "üìä Health status:"
        curl -s http://localhost:8080/health | jq . 2>/dev/null || curl -s http://localhost:8080/health
        echo ""
        echo "üß™ Testing job submission:"
        curl -s -X POST http://localhost:8080/submit \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer test-token" \
            -H "X-Client-ID: fix-test" \
            -d '{"model_name": "test", "input_data": {}}' | jq . 2>/dev/null
        echo ""
        echo "üéâ Gateway fixed and working!"
        exit 0
    else
        echo "‚è≥ Attempt $i/5: Gateway not ready yet..."
        sleep 10
    fi
done

echo "‚ö†Ô∏è  Gateway may still be starting. Check logs:"
echo "docker logs synapse-gateway --tail=20"

echo ""
echo "‚úÖ Fix applied!"
echo ""
echo "üîß What was changed:"
echo "  ‚Ä¢ Replaced aioredis 2.0.1 with redis 5.0.1 (Python 3.11+ compatible)"
echo "  ‚Ä¢ Updated main.py to use redis.asyncio or sync wrapper"
echo "  ‚Ä¢ Added better error handling and fallbacks"
echo "  ‚Ä¢ Improved Dockerfile with build dependencies"
echo "  ‚Ä¢ Rebuilt container with --no-cache to ensure clean build"
